# -*- coding: utf-8 -*-
"""livercirrhosisfinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aHKS0IahiueqxXDWEQkkfjaRjZqkseJe
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/liver_cirrhosis.csvmissing.csv')

#first five rows
df.head()

#last five rows
df.tail()

df.shape

#to print all columns
df.columns

#to print datatypes
df.dtypes

#Finding the number of rows and columns in the dataset

print("Number of rows: ",df.shape[0])
print("Number of columns: ",df.shape[1])

df.info()

df.describe()

#To find missing valuues
df.isna().sum()

# Fill specific columns: SGOT, Cholesterol, and Albumin using their median
columns_to_fill = ['SGOT', 'Cholesterol', 'Albumin']

for col in columns_to_fill:
    if col in df.columns:
        median_value = df[col].median()
        df[col].fillna(median_value, inplace=True)
        print(f"Filled missing values in '{col}' with median: {median_value}")
    else:
        print(f"Column '{col}' not found in the dataset.")

#after removing missing values
df.isna().sum()

#Checking for Duplicated data
df.duplicated().sum()

#To drop duplicate values
df.drop_duplicates(inplace=True)

#The values in Age column are given in days, so we convert them into years, since it will be convenient for us to tackle them.
#We also convert the values in column N_Days into years and store them in a new column N_Years for the same reason.
#We drop the column N_Days.

df['Age']=round(df['Age']/365)
df['N_Years'] = round(df['N_Days']/365)
df.drop(['N_Days'],axis=1,inplace=True)

df

df.columns

#To check the data is balanced on imbalanced
print("No: of class labels",df['Stage'].nunique())
print("class labels",df['Stage'].unique())
df['Stage'].value_counts()

#checking data is balanced or imbalanced

fig,axes=plt.subplots(1,2,figsize=(8,4),dpi=130)
fig.suptitle('Distribution of Histologic Stages of Disease')

a= sns.countplot(data=df,x='Stage',ax=axes[0])
for i in a.containers:
    a.bar_label(i,)

df['Stage'].value_counts().plot(kind='pie',autopct='%2f',startangle=140,ax=axes[1])
axes[1].legend(['Stage 1', 'Stage 2','Stage 3'],loc=(1,0))

fig.tight_layout();

print(df['Status'].value_counts())

print(df['Drug'].value_counts())

"""EDA"""

#Distribution of status of the patient
plt.figure(figsize=(7,4),dpi=120)
ax=sns.countplot(data=df,x="Status",palette="inferno",hue='Stage')
for i in ax.containers:
    ax.bar_label(i,)
plt.title('Distribution of status of the patient')

#To represent the number of people that were given placebo or D-penicillamine.
plt.figure(figsize=(7,4),dpi=130)
ax=sns.countplot(data=df,x="Drug",palette='inferno',hue='Stage')
for i in ax.containers:
    ax.bar_label(i,)
plt.title('Distribution of Types of drug');

print(df['Sex'].value_counts())

#To represent the number of Stage 1, Stage 2 and Stage 3 patients that were found from the two genders.

# Set up the figure
plt.figure(figsize=(7, 4), dpi=130)
plt.title('Distribution of Gender: M(Male) or F(Female)', fontsize=14)

# Create the countplot with hue by Stage
ax = sns.countplot(data=df, x="Sex", hue="Stage", palette='Spectral')

# Add count labels on top of bars
for container in ax.containers:
    ax.bar_label(container, fontsize=9)

# Final layout tweaks
plt.xlabel("Gender")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

#Distribution of Presence of Ascites among the patients

fig, axes = plt.subplots(1,2,figsize=(8,4),dpi=120)

fig.suptitle('Distribution of Presence of Ascites among the patients')

a =sns.countplot(data=df,x='Ascites',hue='Stage',ax=axes[0])
for i in a.containers:
    a.bar_label(i,)

df['Ascites'].value_counts().plot(kind='pie',autopct='%2f',startangle=140,cmap='Accent',ax=axes[1])
axes[1].legend(['N (No)', 'Y (Yes)'],loc=(1,0))

fig.tight_layout();

#Distribution of Presence of Hepatomegaly among the patients

fig,axes = plt.subplots(1,2,figsize=(8,4),dpi=120)
fig.suptitle('Distribution of Presence of Hepatomegaly among the patients')

a = sns.countplot(data=df,x='Hepatomegaly',hue='Stage',ax=axes[0])
for i in a.containers:
    a.bar_label(i,)
df['Hepatomegaly'].value_counts().plot(kind='pie',autopct='%2f',startangle=140,cmap='Set1',ax=axes[1])
axes[1].legend(['N (No)', 'Y (Yes)'],bbox_to_anchor=(1, 0));

#Distribution of Presence of Spiders among the patients

fig,axes=plt.subplots(1,2,figsize=(8,4),dpi=125)
fig.suptitle('Distribution of Presence of Spiders among the patients');

a= sns.countplot(data=df,x='Spiders',hue='Stage',ax=axes[0])
for i in a.containers:
    a.bar_label(i,)
df['Spiders'].value_counts().plot(kind='pie',autopct='%2f',startangle=140,cmap='Paired',ax=axes[1])
axes[1].legend(['N (No)', 'Y (Yes)'],bbox_to_anchor=(1, 0));

#Distribution of Presence of Edema among the patients

fig,axes=plt.subplots(1,2,figsize=(8,4),dpi=200)
fig.suptitle('Distribution of Presence of Edema among the patients');

a= sns.countplot(data=df,x='Edema',hue='Stage',ax=axes[0])
for i in a.containers:
    a.bar_label(i,)
df['Edema'].value_counts().plot(kind='pie',autopct='%2f',startangle=140,cmap='Pastel1',ax=axes[1])
axes[1].legend(['N (no edema and no diuretic therapy for edema)', 'S (edema present without diuretics, or edema resolved by diuretics)', 'Y (edema despite diuretic therapy)'],bbox_to_anchor=(1.8, 0));

#pair plot

df_num = df.select_dtypes(['int','Float64'])
col = list(df_num.drop('Stage',axis=1).columns)
fig, axes= plt.subplots(4,3,figsize=(20, 15))
k=0
for i in range(4):
    for j in range(3):
        if (k< len(col)):
            sns.kdeplot(data=df,x=col[k],ax=axes[i,j],palette='tab10',fill=True,hue='Stage')
            axes[i,j].set_title(f'KDE Plot of {col[k]}')
            k+=1
        else:
            axes[i, j].axis('off')
plt.tight_layout();

#Checking for outliers
col = list(df_num.drop(['Stage','N_Years','Age'],axis=1).columns)
fig, axes= plt.subplots(3,3,figsize=(20, 15))
k=0
for i in range(3):
    for j in range(3):
        if (k< len(col)):
            sns.boxplot(data=df,x='Stage',y=col[k],ax=axes[i,j],palette='tab10')
            axes[i,j].set_title(f'Box Plot of {col[k]}')
            k+=1
        else:
            axes[i, j].axis('off')
plt.tight_layout();

plt.figure(figsize=(6,4),dpi=150)
sns.boxplot(data=df,x='Stage',y='Age',palette='tab10');

plt.figure(figsize=(12,6),dpi=130)
sns.heatmap(df_num.corr(),annot=True,cmap='crest');

"""DATA PREPERATION"""

from sklearn.preprocessing import LabelEncoder
LE = LabelEncoder()
categ = ['Status','Drug', 'Sex', 'Ascites',	'Hepatomegaly',	'Spiders',	'Edema']
df[categ] = df[categ].apply(LE.fit_transform)

df

#checking for outlier

col = list(df_num.drop(['Stage','N_Years','Age'],axis=1).columns)
fig, axes= plt.subplots(3,3,figsize=(20, 15))
k=0
for i in range(3):
    for j in range(3):
        if (k< len(col)):
            sns.boxplot(data=df,x=col[k],ax=axes[i,j],palette='Set2')
            axes[i,j].set_title(f'Box Plot of {col[k]}')
            k+=1
        else:
            axes[i, j].axis('off')
plt.tight_layout();

#Remove outlier using outlier capping

def outlier(a):
    Q1 = a.quantile(0.25)
    Q3 = a.quantile(0.75)
    IQR = Q3-Q1
    L = Q1 - 1.5*IQR
    U = Q3 + 1.5*IQR
    return(L,U)

def cap(a):
    for i in a:
        df.loc[df[i] >= outlier(df[i])[1],i] = outlier(df[i])[1]
        df.loc[df[i] <= outlier(df[i])[0],i] = outlier(df[i])[0]

cap(df_num.drop('Stage',axis=1))

col = list(df_num.drop(['Stage','N_Years','Age'],axis=1).columns)
fig, axes= plt.subplots(3,3,figsize=(20, 15))
k=0
for i in range(3):
    for j in range(3):
        if (k< len(col)):
            sns.boxplot(data=df,x=col[k],ax=axes[i,j],palette='Set2')
            axes[i,j].set_title(f'Box Plot of {col[k]}')
            k+=1
        else:
            axes[i, j].axis('off')
plt.tight_layout();

x = df.drop(columns=['Stage'],axis=1)
y = df['Stage']

x

y

#Splitting of data
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)

#Normalization or scaling
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(x_train)
x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

x_train

x_test

"""Model Building"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

from sklearn.model_selection import GridSearchCV
param_rfc = {'n_estimators': [int(x) for x in np.linspace(start=10,stop=80,num=10)],
             'max_features': ['log2','sqrt',None],
             'max_depth':[2,4,7,10]}
rfc_model = RandomForestClassifier()
gs_rfc_model = GridSearchCV(estimator=rfc_model,param_grid = param_rfc,cv=3,n_jobs=4,error_score='raise')
gs_rfc_model.fit(x_train,y_train)

gs_rfc_model.best_params_

rfc_model = gs_rfc_model.best_estimator_

rfc_preds = rfc_model.predict(x_test)

rfc_preds

y_test

from sklearn.metrics import classification_report, accuracy_score
accuracy = accuracy_score(y_test,rfc_preds)
print(accuracy)

#confusion_matrix
conf_mat = confusion_matrix(y_test,rfc_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='coolwarm', xticklabels=[1, 2, 3], yticklabels=[1, 2, 3])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

print(classification_report(y_test,rfc_preds))

#To find Important features
import matplotlib.pyplot as plt
importances = gs_rfc_model.best_estimator_.feature_importances_
feat_names = x.columns

# Plot
plt.figure(figsize=(10,6))
plt.barh(feat_names, importances)
plt.xlabel("Feature Importance")
plt.title("Random Forest Feature Importance")
plt.tight_layout()
plt.show()